{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "psG2CJDm_oY0"
   },
   "source": [
    "# 概要\n",
    "\n",
    "- タスク：チャットボット\n",
    "- モデル：LSTM を用いた seq2seq\n",
    "- 学習データ：[コーネル映画会話コーパス](https://www.cs.cornell.edu/~cristian/Cornell_Movie-Dialogs_Corpus.html)（[参考](https://db-event.jpn.org/deim2016/papers/81.pdf)）\n",
    "\n",
    "頭から実行していっても良いが、加工と学習にそこそこ時間がかかる。\n",
    "\n",
    "学習済みの結果を使うには、下記のファイルが入った chatbot ディレクトリを GoogleDrive のルート直下に置く。\n",
    "（Google Colab ではなくローカルで動かす場合は、任意の場所に置いて、以降のセルの絶対パスを適宜書き換える）\n",
    "- `encoder_20epoch.pt`\n",
    "- `decoder_20epoch.pt`\n",
    "- `index2word_CornellMovie.pkl`\n",
    "- `word2index_CornellMovie.pkl`\n",
    "\n",
    "そうすると、全てのセルを実行する必要がなく、\n",
    "下記のセクションだけ実行すればチャットボットを動かせる。\n",
    "- 環境設定\n",
    "- ライブラリのインポート\n",
    "- Encoder, Decoder の定義\n",
    "- モデル等の読み込み\n",
    "- チャットボットの補助的な関数を定義\n",
    "- チャットボットの関数を定義\n",
    "- チャットボットを動かす\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cjBgkeOGBwZr"
   },
   "source": [
    "# 環境設定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 122
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 20698,
     "status": "ok",
     "timestamp": 1596178775523,
     "user": {
      "displayName": "Rui ds",
      "photoUrl": "",
      "userId": "05602141477976220902"
     },
     "user_tz": -540
    },
    "id": "TiJFPjQB_WYP",
    "outputId": "8d13809e-24e5-49c1-cb69-fe7b2da6a55e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
      "\n",
      "Enter your authorization code:\n",
      "··········\n",
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "# Google Colab をマウント\n",
    "# 参考：https://qiita.com/k_uekado/items/45b76f9a6f920bf0f786\n",
    "\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# 左サイドバーから確認できるように、\n",
    "# GoogleDrive のルートが colab の drive/My Drive/ にマウントされてる。\n",
    "# ローカルで動かす場合は実行しなくて良い。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3565,
     "status": "ok",
     "timestamp": 1596178787279,
     "user": {
      "displayName": "Rui ds",
      "photoUrl": "",
      "userId": "05602141477976220902"
     },
     "user_tz": -540
    },
    "id": "3ZUlVli3AouG",
    "outputId": "935627b9-3477-46bf-8175-09020471d4fa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "# GPU 設定\n",
    "# 参考：https://qiita.com/tomo_makes/items/f70fe48c428d3a61e131\n",
    "# ランタイム -> ランタイムのタイプ変更 -> ハードウェアアクセラレータに GPU\n",
    "\n",
    "import torch\n",
    "\n",
    "print(torch.cuda.is_available())\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zAIWVgt0B3DS"
   },
   "source": [
    "# ライブラリのインポート"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 704,
     "status": "ok",
     "timestamp": 1596178821649,
     "user": {
      "displayName": "Rui ds",
      "photoUrl": "",
      "userId": "05602141477976220902"
     },
     "user_tz": -540
    },
    "id": "5jM1motrBo9F"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import csv\n",
    "import random\n",
    "import re\n",
    "import os\n",
    "import unicodedata\n",
    "import codecs\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0y4eWrNtC4lz"
   },
   "source": [
    "# コーネル映画対話データの前処理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 187
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 582,
     "status": "ok",
     "timestamp": 1596169008322,
     "user": {
      "displayName": "Rui ds",
      "photoUrl": "",
      "userId": "05602141477976220902"
     },
     "user_tz": -540
    },
    "id": "cH6JMHh0B07k",
    "outputId": "04c069e6-2f88-4fd2-8163-66debe54fdb4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'L1045 +++$+++ u0 +++$+++ m0 +++$+++ BIANCA +++$+++ They do not!\\n'\n",
      "b'L1044 +++$+++ u2 +++$+++ m0 +++$+++ CAMERON +++$+++ They do to!\\n'\n",
      "b'L985 +++$+++ u0 +++$+++ m0 +++$+++ BIANCA +++$+++ I hope so.\\n'\n",
      "b'L984 +++$+++ u2 +++$+++ m0 +++$+++ CAMERON +++$+++ She okay?\\n'\n",
      "b\"L925 +++$+++ u0 +++$+++ m0 +++$+++ BIANCA +++$+++ Let's go.\\n\"\n",
      "b\"u0 +++$+++ u2 +++$+++ m0 +++$+++ ['L194', 'L195', 'L196', 'L197']\\n\"\n",
      "b\"u0 +++$+++ u2 +++$+++ m0 +++$+++ ['L198', 'L199']\\n\"\n",
      "b\"u0 +++$+++ u2 +++$+++ m0 +++$+++ ['L200', 'L201', 'L202', 'L203']\\n\"\n",
      "b\"u0 +++$+++ u2 +++$+++ m0 +++$+++ ['L204', 'L205', 'L206']\\n\"\n",
      "b\"u0 +++$+++ u2 +++$+++ m0 +++$+++ ['L207', 'L208']\\n\"\n"
     ]
    }
   ],
   "source": [
    "# 見てみる\n",
    "\n",
    "corpus_name = \"cornell movie-dialogs corpus\"\n",
    "corpus = \"/content/drive/My Drive/chatbot/data/\" + corpus_name\n",
    "\n",
    "def printLines(file, n=10):\n",
    "    \"\"\" 表示用関数\n",
    "    file の n 行目までを出力する。\n",
    "    \"\"\"\n",
    "    with open(file, 'rb') as datafile:\n",
    "        lines = datafile.readlines()\n",
    "    for line in lines[:n]:\n",
    "        print(line)\n",
    "\n",
    "printLines(os.path.join(corpus, \"movie_lines.txt\"), n=5)\n",
    "printLines(os.path.join(corpus, \"movie_conversations.txt\"), n=5)\n",
    "# フォーマットの詳細はダウンロード元の\n",
    "# https://www.cs.cornell.edu/~cristian/Cornell_Movie-Dialogs_Corpus.html\n",
    "# を参照。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZvuRnMSnJrLZ"
   },
   "source": [
    "## 前処理その１（フォーマットまわり）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "X_RINaS-B0Cs"
   },
   "outputs": [],
   "source": [
    "# 加工用の関数の定義１（フォーマットまわり）\n",
    "\n",
    "\n",
    "def loadLines(fileName, fields):\n",
    "    \"\"\" 各行の文ををカラムに分割\n",
    "    fileName の各行を、fields に指定されたフィールド (カラム) に分割。\n",
    "    結果を dict で返す。\n",
    "    \"\"\"\n",
    "    lines = {}\n",
    "    with open(fileName, 'r', encoding='iso-8859-1') as f:\n",
    "        for line in f:\n",
    "            values = line.split(\" +++$+++ \")\n",
    "            # Extract fields\n",
    "            lineObj = {}\n",
    "            for i, field in enumerate(fields):\n",
    "                lineObj[field] = values[i]\n",
    "            lines[lineObj['lineID']] = lineObj\n",
    "    return lines\n",
    "\n",
    "\n",
    "def loadConversations(fileName, lines, fields):\n",
    "    \"\"\" loadLines で得られた各行を movie_conversations.txt に基づく会話へグループ分け。\n",
    "    loadLines で１セリフを１メンバとした dict を作った。\n",
    "    ここに対話情報を合わせて「１対話ごとに１要素のリスト」を作る。\n",
    "    誰と誰が対話してて、みたいな。\n",
    "    \"\"\"\n",
    "    conversations = []\n",
    "    with open(fileName, 'r', encoding='iso-8859-1') as f:\n",
    "        for line in f:\n",
    "            values = line.split(\" +++$+++ \")\n",
    "            # Extract fields\n",
    "            convObj = {}\n",
    "            for i, field in enumerate(fields):\n",
    "                convObj[field] = values[i]\n",
    "            # Convert string to list (convObj[\"utteranceIDs\"] == \"['L598485', 'L598486', ...]\")\n",
    "            utterance_id_pattern = re.compile('L[0-9]+')\n",
    "            lineIds = utterance_id_pattern.findall(convObj[\"utteranceIDs\"])\n",
    "            # Reassemble lines\n",
    "            convObj[\"lines\"] = []\n",
    "            for lineId in lineIds:\n",
    "                convObj[\"lines\"].append(lines[lineId])\n",
    "            conversations.append(convObj)\n",
    "    return conversations\n",
    "\n",
    "\n",
    "def extractSentencePairs(conversations):\n",
    "    \"\"\"\n",
    "    送信と返信を分けるってのをやってる。\n",
    "    \"\"\"\n",
    "    qa_pairs = []\n",
    "    for conversation in conversations:\n",
    "        # Iterate over all the lines of the conversation\n",
    "        for i in range(len(conversation[\"lines\"]) - 1):  # We ignore the last line (no answer for it)\n",
    "            inputLine = conversation[\"lines\"][i][\"text\"].strip()\n",
    "            targetLine = conversation[\"lines\"][i+1][\"text\"].strip()\n",
    "            # Filter wrong samples (if one of the lists is empty)\n",
    "            if inputLine and targetLine:\n",
    "                qa_pairs.append([inputLine, targetLine])\n",
    "    return qa_pairs\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 258
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2926,
     "status": "ok",
     "timestamp": 1596169424973,
     "user": {
      "displayName": "Rui ds",
      "photoUrl": "",
      "userId": "05602141477976220902"
     },
     "user_tz": -540
    },
    "id": "7fSv8meyDarP",
    "outputId": "ac4b3f5c-b679-4b07-b34c-948ddecbb86f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing corpus...\n",
      "\n",
      "Loading conversations...\n",
      "\n",
      "Writing newly formatted file...\n",
      "\n",
      "Sample lines from file:\n",
      "b\"Can we make this quick?  Roxanne Korrine and Andrew Barrett are having an incredibly horrendous public break- up on the quad.  Again.\\tWell, I thought we'd start with pronunciation, if that's okay with you.\\n\"\n",
      "b\"Well, I thought we'd start with pronunciation, if that's okay with you.\\tNot the hacking and gagging and spitting part.  Please.\\n\"\n",
      "b\"Not the hacking and gagging and spitting part.  Please.\\tOkay... then how 'bout we try out some French cuisine.  Saturday?  Night?\\n\"\n",
      "b\"You're asking me out.  That's so cute. What's your name again?\\tForget it.\\n\"\n",
      "b\"No, no, it's my fault -- we didn't have a proper introduction ---\\tCameron.\\n\"\n"
     ]
    }
   ],
   "source": [
    "# 加工の実行１\n",
    "\n",
    "\n",
    "# 加工後のデータをこのファイルに書き込む\n",
    "datafile = \"/content/drive/My Drive/chatbot/data/\" + \"formatted_movie_lines.txt\"\n",
    "\n",
    "# 送信返信の区切り文字としてタブ'\\t'を使用。\n",
    "delimiter = '\\t'\n",
    "# '\\t' をエスケープ文字として扱わせない\n",
    "delimiter = str(codecs.decode(delimiter, \"unicode_escape\"))\n",
    "\n",
    "\n",
    "lines = {}\n",
    "conversations = []\n",
    "# 完成形テーブル2つのフィールド(カラム)名をセット。\n",
    "MOVIE_LINES_FIELDS = [\"lineID\", \"characterID\", \"movieID\", \"character\", \"text\"]\n",
    "MOVIE_CONVERSATIONS_FIELDS = [\"character1ID\", \"character2ID\", \"movieID\", \"utteranceIDs\"]\n",
    "\n",
    "\n",
    "# プレーンテキストの各行を MOVIE_LINES_FIELDS に指定したフィールド(カラム)に分割。\n",
    "print(\"\\nProcessing corpus...\")\n",
    "lines = loadLines(os.path.join(corpus, \"movie_lines.txt\"), MOVIE_LINES_FIELDS)\n",
    "\n",
    "# 上記の lines は「１セリフ１メンバの dict」だが、これを「１対話１要素のリスト」にする。\n",
    "print(\"\\nLoading conversations...\")\n",
    "conversations = loadConversations(os.path.join(corpus, \"movie_conversations.txt\"),\n",
    "                                  lines, MOVIE_CONVERSATIONS_FIELDS)\n",
    "\n",
    "\n",
    "# ファイル書き込み（初回のみ実行）\n",
    "# 上記で得られた結果を、さっき指定した datafile == \"formatted_movie_lines.txt\" に書き込む。\n",
    "# この時に、送信と返信をタブ区切りにしている。\n",
    "print(\"\\nWriting newly formatted file...\")\n",
    "with open(datafile, 'w', encoding='utf-8') as outputfile:\n",
    "    writer = csv.writer(outputfile, delimiter=delimiter, lineterminator='\\n')\n",
    "    for pair in extractSentencePairs(conversations):\n",
    "        writer.writerow(pair)\n",
    "\n",
    "\n",
    "# 見てみる\n",
    "print(\"\\nSample lines from file:\")\n",
    "printLines(datafile, n=5)\n",
    "# 出力ファイル \"formatted_movie_lines.txt\" を開いて見ると良い。\n",
    "# 221282 行ある。送信返信の対がこれだけあるってこと。\n",
    "# \\t で送信と返信がタブ区切りされていることに注目。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Z2vLo-yYFHVZ"
   },
   "source": [
    "formatted_movie_lines.txt の l.211716〜。\n",
    "\n",
    "タブ\\tで分割し、対になってるのを重複消し、並べてみた。\n",
    "\n",
    "こういう自然な対話が入っているデータ。どの映画かの情報は消したが。\n",
    "\n",
    "Can I help you, sir?\n",
    "\n",
    "I need a ticket.\n",
    "\n",
    "Where to?\n",
    "\n",
    "Out of here.\n",
    "\n",
    "But, in particular?\n",
    "\n",
    "I . . . Mexico.  You got a bus that goes to Mexico?  That's where I have to go.\n",
    "\n",
    "Where in Mexico would you like--\n",
    "\n",
    "I don't care, just get me there.\n",
    "\n",
    "We have a bus to Mexico.  Arrives in two hours.  Have to make a couple of connections, but it will get you across the border.\n",
    "\n",
    "How much.\n",
    "\n",
    "One way, or round trip?\n",
    "\n",
    "One way.\n",
    "\n",
    "Thirty even.\n",
    "\n",
    "Twenty-seven fifty.  That's all I got.\t\n",
    "\n",
    "The ticket is thirty dollars.\n",
    "\n",
    "I bought a beer.  That was two- fifty. I bought a beer, otherwise I would have thirty.\n",
    "\n",
    "I'm sorry, sir.  It's thirty dollars for the ticket.\n",
    "\n",
    "Yeah.  Just a little short. Figures.  I just wanted to get out, that's all. Please, you don't understand.  I have to get out of here.  They're going to come looking for me. They're going to kill me.  If I can't get this ticket then I'm going to have to do things to get out of here.  I don't want to hurt anybody, I just want to leave.\n",
    "\n",
    "I'll give you the money!  Okay? I'll give you two-fifty."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Fk0qGNvWJ2cr"
   },
   "source": [
    "## 前処理その２（辞書まわり）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rwnUiagyHPvc"
   },
   "outputs": [],
   "source": [
    "# 加工用の定義２（辞書まわり）\n",
    "\n",
    "\n",
    "PAD_token = 0  # Used for padding short sentences\n",
    "# パディング(短すぎる文の後ろを穴埋め)用\n",
    "\n",
    "SOS_token = 1  # Start-of-sentence token\n",
    "# 文頭を表す文字的\n",
    "\n",
    "EOS_token = 2  # End-of-sentence token\n",
    "# 文末を表す文字的\n",
    "\n",
    "\n",
    "class Voc:\n",
    "    \"\"\"単語の辞書＝Vocabulary\n",
    "    Attributes\n",
    "      trimmed: すでに trim() メソッドが実行されたか。\n",
    "      word2index：単語をIDに変換する dict\n",
    "      word2count：単語を出現回数に変換する dict\n",
    "      index2word：IDを単語に変換する dict\n",
    "    \"\"\"\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        self.trimmed = False\n",
    "        self.word2index = {}\n",
    "        self.word2count = {}\n",
    "        self.index2word = {PAD_token: \"PAD\", SOS_token: \"SOS\", EOS_token: \"EOS\"}\n",
    "        self.num_words = 3  # Count SOS, EOS, PAD\n",
    "\n",
    "    def addSentence(self, sentence):\n",
    "        \"\"\"\n",
    "        文を半スペで分割して単語にして、そのすべての単語に addWord() を適用。\n",
    "        \"\"\"\n",
    "        for word in sentence.split(' '):\n",
    "            self.addWord(word)\n",
    "\n",
    "    def addWord(self, word):\n",
    "        \"\"\"\n",
    "        単語を辞書つまり語彙に追加する。\n",
    "        ついでに出現回数もカウントしている。\n",
    "        \"\"\"\n",
    "        if word not in self.word2index:\n",
    "            self.word2index[word] = self.num_words\n",
    "            self.word2count[word] = 1\n",
    "            self.index2word[self.num_words] = word\n",
    "            self.num_words += 1\n",
    "        else:\n",
    "            self.word2count[word] += 1\n",
    "\n",
    "    # Remove words below a certain count threshold\n",
    "    def trim(self, min_count):\n",
    "        \"\"\"\n",
    "        稀な(出現回数の少ない)単語をトリムする、つまり除去する。\n",
    "        \"\"\"\n",
    "        if self.trimmed:\n",
    "            return\n",
    "        self.trimmed = True\n",
    "\n",
    "        keep_words = []\n",
    "\n",
    "        for k, v in self.word2count.items():\n",
    "            if v >= min_count:\n",
    "                keep_words.append(k)\n",
    "\n",
    "        print('keep_words {} / {} = {:.4f}'.format(\n",
    "            len(keep_words), len(self.word2index), len(keep_words) / len(self.word2index)\n",
    "        ))\n",
    "\n",
    "        # Reinitialize dictionaries\n",
    "        self.word2index = {}\n",
    "        self.word2count = {}\n",
    "        self.index2word = {PAD_token: \"PAD\", SOS_token: \"SOS\", EOS_token: \"EOS\"}\n",
    "        self.num_words = 3 # Count default tokens\n",
    "\n",
    "        for word in keep_words:\n",
    "            self.addWord(word)\n",
    "\n",
    "\n",
    "MAX_LENGTH = 10  # Maximum sentence length to consider\n",
    "# 質問/返答 ともに 10 word 以下の対話の対を、扱う。\n",
    "# それ以外はフィルタかけて取り除いてしまう。まあ後でこのグローバル設定値を使う。\n",
    "# 長期依存性の学習を十分に行えるモデルなら、ここを大きくしても問題ない。\n",
    "\n",
    "\n",
    "# Unicode 文字列を ASCII に変換\n",
    "def unicodeToAscii(s):\n",
    "    return ''.join(\n",
    "        c for c in unicodedata.normalize('NFD', s)\n",
    "        if unicodedata.category(c) != 'Mn'\n",
    "    )\n",
    "\n",
    "\n",
    "# Lowercase, trim, and remove non-letter characters\n",
    "# 上記の unicodeToASCII() を呼んで ASCII にした上で、\n",
    "# すべての文字を小文字に変換し、句読点を除去し、アルファベット以外の文字を除去。\n",
    "# 正規表現で頑張っている。\n",
    "def normalizeString(s):\n",
    "    s = unicodeToAscii(s.lower().strip())\n",
    "    s = re.sub(r\"([.!?])\", r\" \\1\", s)\n",
    "    s = re.sub(r\"[^a-zA-Z.!?]+\", r\" \", s)\n",
    "    s = re.sub(r\"\\s+\", r\" \", s).strip()\n",
    "    return s\n",
    "\n",
    "\n",
    "# Read query/response pairs and return a voc object\n",
    "# 質問/応答 の対を読み込んで上記関数で正規化した上で返却。\n",
    "# その際にタブ\\tで 質問/応答 を分割して、(質問,応答) というタプルでペアにする。\n",
    "# また、辞書 Voc インスタンスを生成して返却。\n",
    "def readVocs(datafile, corpus_name):\n",
    "    print(\"Reading lines...\")\n",
    "    # Read the file and split into lines\n",
    "    lines = open(datafile, encoding='utf-8').\\\n",
    "        read().strip().split('\\n')\n",
    "    # Split every line into pairs and normalize\n",
    "    pairs = [[normalizeString(s) for s in l.split('\\t')] for l in lines]\n",
    "    voc = Voc(corpus_name)\n",
    "    return voc, pairs\n",
    "\n",
    "\n",
    "# グローバルで指定した閾値 MAX_LENGTH より短い文からなる対話(対)かどうかを判定する。\n",
    "# 質問/応答 ともに MAX_LENGTH より短かったら、True を返す。\n",
    "def filterPair(p):\n",
    "    # Input sequences need to preserve the last word for EOS token\n",
    "    return len(p[0].split(' ')) < MAX_LENGTH and len(p[1].split(' ')) < MAX_LENGTH\n",
    "\n",
    "\n",
    "# Filter pairs using filterPair condition\n",
    "# 複数の 質問/応答 に上記フィルターを適用して、一気に判定。\n",
    "def filterPairs(pairs):\n",
    "    return [pair for pair in pairs if filterPair(pair)]\n",
    "\n",
    "\n",
    "# 上記で定義した様々な関数を一気に実行する関数。(アプリケーションサービス）\n",
    "def loadPrepareData(corpus, corpus_name, datafile):\n",
    "    print(\"Start preparing training data ...\")\n",
    "    voc, pairs = readVocs(datafile, corpus_name)\n",
    "    print(\"Read {!s} sentence pairs\".format(len(pairs)))\n",
    "    pairs = filterPairs(pairs)\n",
    "    print(\"Trimmed to {!s} sentence pairs\".format(len(pairs)))\n",
    "    print(\"Counting words...\")\n",
    "    for pair in pairs:\n",
    "        voc.addSentence(pair[0])\n",
    "        voc.addSentence(pair[1])\n",
    "    print(\"Counted words:\", voc.num_words)\n",
    "    return voc, pairs\n",
    "\n",
    "\n",
    "# レア単語判定の閾値。すぐ後ろで使う。\n",
    "MIN_COUNT = 3    # Minimum word count threshold for trimming\n",
    "\n",
    "def trimRareWords(voc, pairs, MIN_COUNT):\n",
    "    # Trim words used under the MIN_COUNT from the voc\n",
    "    \"\"\"\n",
    "    出現回数が MIN_COUNT より小さいレアな単語を、辞書から削除する。\n",
    "    さらに、会話ペアのうち「質問にも応答にもレア単語が含まれていない」ものだけ残し、あとは除去する。\n",
    "    \"\"\"\n",
    "    voc.trim(MIN_COUNT)\n",
    "    # Filter out pairs with trimmed words\n",
    "    keep_pairs = []\n",
    "    for pair in pairs:\n",
    "        input_sentence = pair[0]\n",
    "        output_sentence = pair[1]\n",
    "        keep_input = True\n",
    "        keep_output = True\n",
    "        # Check input sentence\n",
    "        for word in input_sentence.split(' '):\n",
    "            if word not in voc.word2index:\n",
    "                keep_input = False\n",
    "                break\n",
    "        # Check output sentence\n",
    "        for word in output_sentence.split(' '):\n",
    "            if word not in voc.word2index:\n",
    "                keep_output = False\n",
    "                break\n",
    "\n",
    "        # Only keep pairs that do not contain trimmed word(s) in their input or output sentence\n",
    "        if keep_input and keep_output:\n",
    "            keep_pairs.append(pair)\n",
    "\n",
    "    print(\"Trimmed from {} pairs to {}, {:.4f} of total\".format(len(pairs), len(keep_pairs), len(keep_pairs) / len(pairs)))\n",
    "    return keep_pairs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 377
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 12239,
     "status": "ok",
     "timestamp": 1596170004202,
     "user": {
      "displayName": "Rui ds",
      "photoUrl": "",
      "userId": "05602141477976220902"
     },
     "user_tz": -540
    },
    "id": "1HtkugpXIkjc",
    "outputId": "16798281-0860-4366-e6da-8f0c20bf4232"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start preparing training data ...\n",
      "Reading lines...\n",
      "Read 221282 sentence pairs\n",
      "Trimmed to 64271 sentence pairs\n",
      "Counting words...\n",
      "Counted words: 18008\n",
      "{0: 'PAD', 1: 'SOS', 2: 'EOS', 3: 'there', 4: '.', 5: 'where', 6: '?', 7: 'you', 8: 'have', 9: 'my'}\n",
      "{'there': 2013, '.': 104124, 'where': 2475, '?': 43942, 'you': 29248, 'have': 3023, 'my': 3148, 'word': 125, 'as': 558, 'a': 8579}\n",
      "['how many people were in your old school ?', 'thirty two .']\n",
      "['thirty two .', 'get out !']\n",
      "['get out !', 'how many people go here ?']\n",
      "['how many people go here ?', 'couple thousand . most of them evil']\n",
      "['that girl i', 'you burn you pine you perish ?']\n",
      "['you burn you pine you perish ?', 'who is she ?']\n",
      "['yeah just a minor encounter with the shrew .', 'that s her ? bianca s sister ?']\n",
      "['that s her ? bianca s sister ?', 'the mewling rampalian wretch herself .']\n",
      "['what about him ?', 'you wanna go out with him ?']\n",
      "['what makes you think he ll do it ?', 'he seems like he thrives on danger']\n",
      "keep_words 7823 / 18005 = 0.4345\n",
      "Trimmed from 64271 pairs to 53165, 0.8272 of total\n"
     ]
    }
   ],
   "source": [
    "# 加工の実行２\n",
    "\n",
    "\n",
    "# 上の loadPrepareData() を実行して、辞書(vocabulary)と質問応答ペアを取得。\n",
    "voc, pairs = loadPrepareData(corpus, corpus_name, datafile)\n",
    "\n",
    "print({k:voc.index2word[k] for k in list(voc.index2word)[:10]})\n",
    "print({k:voc.word2count[k] for k in list(voc.word2count)[:10]})\n",
    "\n",
    "for pair in pairs[40:50]:\n",
    "    print(pair)\n",
    "\n",
    "\n",
    "# レアな単語の除去を実行\n",
    "pairs = trimRareWords(voc, pairs, MIN_COUNT)  # voc は内部状態が更新される。\n",
    "# print の通り、20%の会話を削るだけで、50%以上の単語を削ることができている。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Qpq1wQ8bJTaw"
   },
   "source": [
    "## 前処理その３（torch.Tensor化まわり）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "I-POYcQJKHCW"
   },
   "outputs": [],
   "source": [
    "# 加工用の定義３（torch.Tensor化まわり）\n",
    "\n",
    "\n",
    "def indexesFromSentence(voc, sentence):\n",
    "    return [voc.word2index[word] for word in sentence.split(' ')] + [EOS_token]\n",
    "\n",
    "\n",
    "def zeroPadding(l, fillvalue=PAD_token):\n",
    "    return list(itertools.zip_longest(*l, fillvalue=fillvalue))\n",
    "\n",
    "\n",
    "def binaryMatrix(l, value=PAD_token):\n",
    "    m = []\n",
    "    for i, seq in enumerate(l):\n",
    "        m.append([])\n",
    "        for token in seq:\n",
    "            if token == PAD_token:\n",
    "                m[i].append(0)\n",
    "            else:\n",
    "                m[i].append(1)\n",
    "    return m\n",
    "\n",
    "\n",
    "def inputVar(l, voc):\n",
    "    indexes_batch = [indexesFromSentence(voc, sentence) for sentence in l]\n",
    "    lengths = torch.tensor([len(indexes) for indexes in indexes_batch])\n",
    "    padList = zeroPadding(indexes_batch)\n",
    "    padVar = torch.LongTensor(padList).to(device)  # GPU指定\n",
    "    return padVar, lengths\n",
    "\n",
    "\n",
    "def outputVar(l, voc):\n",
    "    indexes_batch = [indexesFromSentence(voc, sentence) for sentence in l]\n",
    "    max_target_len = max([len(indexes) for indexes in indexes_batch])\n",
    "    padList = zeroPadding(indexes_batch)\n",
    "    mask = binaryMatrix(padList)\n",
    "    mask = torch.BoolTensor(mask)\n",
    "    padVar = torch.LongTensor(padList).to(device)  # GPU指定\n",
    "    return padVar, mask, max_target_len\n",
    "\n",
    "\n",
    "def batch2TrainData(voc, pair_batch):\n",
    "    pair_batch.sort(key=lambda x: len(x[0].split(\" \")), reverse=True)\n",
    "    input_batch, output_batch = [], []\n",
    "    for pair in pair_batch:\n",
    "        input_batch.append(pair[0])\n",
    "        output_batch.append(pair[1])\n",
    "    inp, lengths = inputVar(input_batch, voc)\n",
    "    output, mask, max_target_len = outputVar(output_batch, voc)\n",
    "    return inp, lengths, output, mask, max_target_len\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 309
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 649,
     "status": "ok",
     "timestamp": 1596171221037,
     "user": {
      "displayName": "Rui ds",
      "photoUrl": "",
      "userId": "05602141477976220902"
     },
     "user_tz": -540
    },
    "id": "9VVOsMscKcDx",
    "outputId": "01887996-d723-4cdc-9727-10e32e46f4bb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['your mom take anything before this happened ?', 'yeah but i don t know what .'], ['that requires me goin out tonight ?', 'a bit .'], ['certainly . right over there .', 'you re all right .'], ['come on .', 'no . no no no .'], ['maybe .', 'don t you care ?']]\n",
      "input_variable:\n",
      " tensor([[  70, 1119,  218,  371,  129,   45,  368,    6,    2],\n",
      "        [  36, 4458,   83,  212,   21,   22,    6,    2,    0],\n",
      "        [2387,    4,  266,  935,    3,    4,    2,    0,    0],\n",
      "        [ 401,  177,    4,    2,    0,    0,    0,    0,    0],\n",
      "        [ 287,    4,    2,    0,    0,    0,    0,    0,    0]],\n",
      "       device='cuda:0')\n",
      "target_variable:\n",
      " tensor([[ 167,   42,   25,  197,  117,   24,   50,    4,    2],\n",
      "        [  12, 1947,    4,    2,    0,    0,    0,    0,    0],\n",
      "        [   7,   14,   38,  266,    4,    2,    0,    0,    0],\n",
      "        [  34,    4,   34,   34,   34,    4,    2,    0,    0],\n",
      "        [ 197,  117,    7,  280,    6,    2,    0,    0,    0]],\n",
      "       device='cuda:0')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 9])"
      ]
     },
     "execution_count": 33,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 一部加工してみる\n",
    "# 学習の際は、ミニバッチサンプリングの後に毎回、batch2TrainData() を呼び出して使う。\n",
    "\n",
    "\n",
    "small_batch_size = 5     # とりあえず 5 つの会話について加工前後を見る。\n",
    "\n",
    "# 加工本体\n",
    "tmp = [random.choice(pairs) for _ in range(small_batch_size)]\n",
    "batches = batch2TrainData(voc, tmp)\n",
    "print(tmp)  # small_batch_size分の会話ペア。\n",
    "\n",
    "# 返却値のタプルを分ける\n",
    "input_variable, lengths, target_variable, mask, max_target_len = batches\n",
    "\n",
    "print(\"input_variable:\\n\", input_variable.T)\n",
    "input_variable.T.shape\n",
    "input_variable.T[1]\n",
    "# 元の会話バッチ tmp の質問文の方を ID 化したもの。\n",
    "# MAX_LENGTH = 10 で 質問/返答 ともに 10 word 以下の対話の対を扱い、\n",
    "# かつ、ゼロパディングするので、\n",
    "# 横のサイズが 10 以下(バッチ内の最長にものに合わさるようになってる)になっている。\n",
    "# 縦のサイズはもちろん質問文の数つまり会話バッチサイズ。\n",
    "# <EOS> の ID が 2 ってことにも注意。\n",
    "\n",
    "\n",
    "# print(\"target_variable:\", target_variable)\n",
    "print(\"target_variable:\\n\", target_variable.T)\n",
    "target_variable.T.shape\n",
    "# input_variable の応答文バージョン。モデル的にはターゲット(アウトカム)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gkpo9ApgMHiO"
   },
   "source": [
    "# Encoder, Decoder の定義"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 554,
     "status": "ok",
     "timestamp": 1596178836554,
     "user": {
      "displayName": "Rui ds",
      "photoUrl": "",
      "userId": "05602141477976220902"
     },
     "user_tz": -540
    },
    "id": "o73AhfWYOUhU"
   },
   "outputs": [],
   "source": [
    "\n",
    "class Encoder(nn.Module):\n",
    "    \"\"\" Encoder in seq2seq\n",
    "    \n",
    "    質問文を処理する Encoder で、系列データを文脈ベクトルに変換する。\n",
    "    \n",
    "    LSTM を使っているが、GRU や Elman RNN でも OK。\n",
    "    ここを他のものに変えて比較等できれば良いと思う(が、計算時間、、、)\n",
    "\n",
    "    最終 LSTM ユニットの状態 h と記憶 c を合わせたものを文脈ベクトルとし、decoder に引き継ぐ。 \n",
    "    \n",
    "    nn.LSTM クラスについては、公式ドキュメント\n",
    "    https://pytorch.org/docs/master/generated/torch.nn.LSTM.html\n",
    "    が分かりやすい。\n",
    "\n",
    "    backward()は「PyTorch用データ型 torch.Tensor 自体」に実装されている。\n",
    "    \n",
    "    Attributes:\n",
    "      hidden_dim：コンストラクタ参照。\n",
    "      word_embeddings： embedding レイヤ。系列の数だけまとめたもの。\n",
    "      lstm： LSTM レイヤ。系列の数だけまとまってる。\n",
    "    \n",
    "    \"\"\"\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim):\n",
    "        \"\"\" initialization\n",
    "        Args:\n",
    "          vocab_size：語彙数。つまり embedding レイヤの入力の次元。\n",
    "          embedding_dim：単語を埋め込む次元。embedding レイヤの出力の次元。\n",
    "          hidden_dim：状態hの次元＝記憶cの次元。モデル式の通り LSTM では同じ。\n",
    "        \"\"\"\n",
    "        super(Encoder, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.word_embeddings = nn.Embedding(vocab_size, embedding_dim, padding_idx=0)\n",
    "        # padding_idx=0 はパディング文字の ID は 0 にしてあります、という意味。\n",
    "        # 効果は https://takoroy-ai.hatenadiary.jp/entry/2018/07/02/224216\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, batch_first=True)\n",
    "        # batch_first=True としておくと、forward の入出力のテンソルの形状が、\n",
    "        # (batch, seq, feature) つまり (文数, 単語数, 次元数) になる。\n",
    "\n",
    "    def forward(self, sequence):\n",
    "        \"\"\" forward propagation\n",
    "        入力系列 -> 文脈ベクトル(最終ユニットの状態と記憶)\n",
    "        nn.Module を継承してるので Encoder インスタンスを関数ぽく呼んだ時に、\n",
    "        この forward が呼び出され実行される。明示しても良いが。\n",
    "        Args:\n",
    "          sequence：質問文のバッチ。ID化されて int になってる状態。\n",
    "        \"\"\"\n",
    "        # 前述の仕組みで embedding の forward つまり単語埋め込みが実行されてる。\n",
    "        embedding = self.word_embeddings(sequence)\n",
    "        # 後述の通り「最終LSTMユニットの状態+記憶」は 2 番目の返却値。これが encoder の出力つまり文脈ベクトル。\n",
    "        _, state = self.lstm(embedding)\n",
    "        return state\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 877,
     "status": "ok",
     "timestamp": 1596178869687,
     "user": {
      "displayName": "Rui ds",
      "photoUrl": "",
      "userId": "05602141477976220902"
     },
     "user_tz": -540
    },
    "id": "XoXejSpSOYuh"
   },
   "outputs": [],
   "source": [
    "\n",
    "class Decoder(nn.Module):\n",
    "    \"\"\" Decoder in seq2seq\n",
    "\n",
    "    回答文を生成する Decoder で、文脈ベクトルを系列データに変換する。\n",
    "    LSTM を使っているが、GRU や Elman RNN でも OK。\n",
    "    初期時点の状態と記憶に、文脈ベクトル(Encoder の最終 LSTM ユニットの状態 h と記憶 c)を使っている。\n",
    "    \n",
    "    nn.Linear クラスについては、公式ドキュメント\n",
    "    https://pytorch.org/docs/master/generated/torch.nn.Linear.html\n",
    "    が分かりやすい。\n",
    "\n",
    "    backward()は「PyTorch用データ型 torch.Tensor 自体」に実装されている。\n",
    "    \n",
    "    softmax は Decoder には入れない。ロス のとこに入れる。\n",
    "    \n",
    "    Attributes:\n",
    "      hidden_dim：コンストラクタ参照。\n",
    "      word_embeddings： embedding レイヤ。複数系列分。\n",
    "      lstm： LSTM レイヤ。複数系列分のユニットのかたまり。\n",
    "      hidden2linear：線形(Affine)変換レイヤ。隠れ状態をAffine変換して単語出現スコアにしてる。\n",
    "    \n",
    "    \"\"\"\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "          vocab_size：語彙数。つまり Linear(Affine) レイヤの出力の次元。\n",
    "          embedding_dim：単語を埋め込む次元。embedding レイヤの出力の次元。\n",
    "          hidden_dim：状態hの次元＝記憶cの次元。モデル式の通り LSTM では同じ。\n",
    "        今回は、Encoder と Decoder で別ルールで埋め込みする。\n",
    "        なので、embedding_dim については Encoder の方と一致している必要はない。\n",
    "        hidden_dim は一致していないとダメ。文脈を引き継げない。\n",
    "        \"\"\"\n",
    "        super(Decoder, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.word_embeddings = nn.Embedding(vocab_size, embedding_dim, padding_idx=0)\n",
    "        # padding_idx=0 はパディング文字の ID は 0 にしてあります、という意味。\n",
    "        # 効果は https://takoroy-ai.hatenadiary.jp/entry/2018/07/02/224216\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, batch_first=True)\n",
    "        # batch_first=True としておくと、forward の入出力のテンソルの形状が、\n",
    "        # (batch, seq, feature) つまり (文数, 単語数, 次元数) になる。\n",
    "        self.hidden2linear = nn.Linear(hidden_dim, vocab_size)\n",
    "\n",
    "    def forward(self, sequence, encoder_state):\n",
    "        \"\"\" forward propagation\n",
    "        文脈ベクトル(Encoder最終ユニットの状態と記憶) -> 出力系列\n",
    "        nn.Module を継承してるので Encoder インスタンスを関数ぽく呼んだ時に、\n",
    "        この forward が呼び出され実行される。明示しても良いが。\n",
    "        Args:\n",
    "          sequence: 教師強制学習の際は応答文のバッチ。予測(推論)の際は1つ前で生成された単語？\n",
    "        \"\"\"\n",
    "        embedding = self.word_embeddings(sequence)\n",
    "        # 前述の通り、第1返却値が「全時点ユニットにおける隠れ状態」なので、教師強制学習の時はこれそのまま使える。\n",
    "        # また、第2返却値は「最終ユニットの隠れ状態+記憶」で、予測(推論)の際は文を作り続けるので必要。\n",
    "        output, state = self.lstm(embedding, encoder_state)\n",
    "        output = self.hidden2linear(output)\n",
    "        return output, state\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4EObWUuMOZPV"
   },
   "source": [
    "# モデルの作成・ハイパーパラメータ的要素の設定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "V9Iu_n-KOmPi"
   },
   "outputs": [],
   "source": [
    "\n",
    "# モデルのハイパーパラメータ設定と作成\n",
    "\n",
    "word_embedding_dim = 500  # 単語を埋め込む次元。encoder と decoder で共有しよう。\n",
    "state_memory_dim = 500    # 状態・記憶の次元\n",
    "\n",
    "encoder = Encoder(\n",
    "    vocab_size=len(voc.index2word),\n",
    "    embedding_dim= word_embedding_dim,\n",
    "    hidden_dim=state_memory_dim\n",
    ").to(device)  # GPU指定\n",
    "\n",
    "decoder = Decoder(\n",
    "    vocab_size=len(voc.index2word),\n",
    "    embedding_dim=word_embedding_dim,\n",
    "    hidden_dim=state_memory_dim\n",
    ").to(device)  # GPU指定\n",
    "\n",
    "\n",
    "# 学習の設定 (ハイパーパラメータとみなせる)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()  # ロス指標\n",
    "# CrossEntropyLoss には softmax 変換も入っている。\n",
    "\n",
    "encoder_optimizer = optim.Adam(encoder.parameters(), lr=0.001)\n",
    "decoder_optimizer = optim.Adam(decoder.parameters(), lr=0.001)\n",
    "# とりあえず Adam を使っておく。\n",
    "\n",
    "batch_size = 64\n",
    "iter_per_epoch = int(len(pairs) / batch_size)\n",
    "epoch_num = 20\n",
    "# iter_per_epoch = 10\n",
    "# epoch_num = 10\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QrzNvUYNPHT2"
   },
   "source": [
    "# 学習の実行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 964
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 243191,
     "status": "ok",
     "timestamp": 1596173165568,
     "user": {
      "displayName": "Rui ds",
      "photoUrl": "",
      "userId": "05602141477976220902"
     },
     "user_tz": -540
    },
    "id": "QqjVj0NmPYJd",
    "outputId": "de2990c1-1e43-47e9-bdf2-4d722c27816c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training ...\n",
      "Epoch 1: 19346.14\n",
      "Epoch 2: 16044.28\n",
      "Epoch 3: 14326.04\n",
      "Epoch 4: 12844.57\n",
      "Epoch 5: 11458.40\n",
      "Epoch 6: 10157.52\n",
      "Epoch 7: 8957.80\n",
      "Epoch 8: 7902.11\n",
      "Epoch 9: 6922.49\n",
      "Epoch 10: 6060.21\n",
      "Epoch 11: 5343.09\n",
      "Epoch 12: 4711.15\n",
      "Epoch 13: 4159.06\n",
      "Epoch 14: 3689.56\n",
      "Epoch 15: 3286.21\n",
      "Epoch 16: 2962.84\n",
      "Epoch 17: 2683.89\n",
      "Epoch 18: 2478.16\n",
      "Epoch 19: 2262.94\n",
      "Epoch 20: 2104.73\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZEAAAEWCAYAAACnlKo3AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3deXwV1f3/8dcnC1vYSUD2TcClIkJYFZdaW5e27opawRWttXb5dtH21+Xb5Vvtt9qvdNGiUkFFcanV1pW6LywGRUQRCcgSCBDWsG/5/P6YE73GJISQe+cmeT8fj3ncuWfOzHzuJLmfnDNnZszdERERqY2MuAMQEZH6S0lERERqTUlERERqTUlERERqTUlERERqTUlERERqTUlEGi0zG21mC+OOIw5mlmdmH5pZ8xhjWGpmX6pi2UAzezPVMcmBUxKRWFT3BZIq7v6auw9I1vbN7Ctm9qqZbTGzEjN7xcy+nqz9HaAbgXvdfQeAmb1sZjvNbGvC9K+4gnP3ecAmM/taXDFIzSiJSINlZpkx7vs84BFgCtAN6AT8HDjgL0WL1Nnfqpk1BcYB91dYdL27t0yY4v4CfwC4JuYYZD+URCStmFmGmd1oZovNbL2ZPWxm7ROWP2Jmq81sc/gv/8iEZfea2R1m9rSZbQNOCi2eH5jZvLDONDNrFuqfaGZFCetXWTcs/5GZFZvZKjO7yszczA6t5DMYcBvwa3e/2903u3uZu7/i7leHOr80s/sT1ukVtpcV3r9sZr81szeA7cAPzaygwn6+Z2ZPhvmmZvYHM1tuZmvM7M5quqqGA5vcvaiK5RU/z4lmVmRmPzGzdeE4XZKwvI2ZTQmtrWVm9v8Sk56ZXW1mC0KL7AMzG5yw+UFVHW/gZeDkkPQkTSmJSLr5NnAWcALQBdgI/CVh+TNAP6Aj8DbRf6uJLgZ+C7QCXg9lFwCnAr2BgcBl1ey/0rpmdirwfeBLwKHAidVsYwDQHXi0mjo1cSkwnuiz3AkMMLN+CcsvBqaG+ZuB/sCgEF9XopZPZY4CDvRc0CFAbtjuOGCimZV3Bf4JaAP0Ifq5jQUuBzCz84FfhrLWwNeB9QnbrfJn4+4rgT1Ex1PSlJKIpJtrgZ+6e5G77yL6Ajqv/D90d5/k7lsSlh1tZm0S1n/C3d8I//nvDGUT3H2Vu28A/kX0RVuVqupeAPzd3d939+1h31XpEF6La/qhq3Bv2N9ed98MPAFcBBCSyWHAk6HlMx74nrtvcPctwP8AY6rYbltgSyXlE8xsU8L06wrLf+buu9z9FeAp4ILQZTgGuCn8XJYCtxIlQICrgN+7+1seKXT3ZYn73M/PZkuIV9KUkoikm57A4+VfZMACYB/Qycwyzezm0NVVCiwN6+QmrL+ikm2uTpjfDrSsZv9V1e1SYduV7adc+X/anaupUxMV9zGVkESIWiH/DAktD2gBzEk4bs+G8spsJGrdVHSDu7dNmH6WuI67b0t4v4zomOQC2eF94rKuYb47sLiaz7i/n00rYFM160vMlEQk3awATqvwZdYsdG1cDJxJ1KXUBugV1rGE9ZN1W+piohPk5bpXU3ch0ec4t5o624i++MsdUkmdip9lOpBnZoOIkkl5V9Y6YAdwZMIxa+PuVSXLeURdXweinZnlJLzvAawK+95DlPwTl60M8yuAvge4LwDMrCvQhAPvepMUUhKROGWbWbOEKYuo7/+3ZtYTPrme4cxQvxWwi+g//RZEXTap8jBwuZkdbmYtgJ9VVdGj5yt8H/iZmV1uZq3DgIHjzGxiqDYXON7MeoTuuJv2F4C77yEa8fW/QHuipIK7lwF3AX80s44QfQGb2Veq2NRsoG34kj4Q/21mTcxsNPBV4BF330d0bH5rZq3Cz+37fDry627gB2Y2xCKHlv9sa+AE4MXQdSlpSklE4vQ00X/Q5dMvgduBJ4HnzWwLMJNoNBFEw2WXEf2X+0FYlhLu/gwwAXgJKEzYd6VfcO7+KHAhcAXRf+xrgN8QndfA3acD04haBXOAf9cwlKlELbFH3H1vQvmPy+MKXX3/oYoT0u6+G7gX+EaFRX+2z14nMidh2WqibrBVRIMZrnX3D8OybxO1rJYQDWaYCkwK+3qEaKDDVKLzG/8kSoA1cQnRPxWSxkwPpRI5cGZ2ODAfaFrhy7xeMLM84DXgmPILDqupeyJwv7t3q65eXTKzgcDf3H1kqvYptaOWiEgNmdnZ4XqMdsAtwL/qYwIBcPcSdz9sfwkkLu4+TwmkflASEam5a4C1RKON9gHfjDcckfipO0tERGpNLREREam1rGRt2My6E42m6UQ03n2iu99u0X2QphGN8V8KXODuG8NVt7cDpxNddHSZu78dtjUO+H9h079x98mhfAjRKJPmRCN9vuP7aVrl5uZ6r1696u6Diog0AnPmzFnn7p+7gDVp3Vlm1hno7O5vm1kromGMZxHdG2eDu99sZjcC7dz9x2Z2OtFQwdOJhnTe7u7DQ9IpAPKJktEcYEhIPLOBG4BZRElkQhiKWaX8/HwvKCioroqIiFRgZnPcPb9iedK6s9y9uLwlEe7ls4DoVghnApNDtclEiYVQPiXcX2cm0cVQnYGvANPDPYE2El1gdWpY1trdZ4bWx5SEbYmISAqk5JyImfUCjiFqMXRy9/Ib060m6u6CKMEk3iuoKJRVV15USXll+x9vZgVmVlBSUnJQn0VERD6V9CRiZi2Bx4Dvuntp4rLQgkj68DB3n+ju+e6en5dX1T3pRETkQCU1iZhZNlECecDd/xGK14SuqPLzJmtD+Uo+e1O7bqGsuvJulZSLiEiKJC2JhNFW9wAL3P22hEVPEj3UhvD6REL52HCTthHA5tDt9RzwZTNrF64U/jLwXFhWamYjwr7GJmxLRERSIGlDfIFjiR5M856ZzQ1lPyF6AtvDZnYl0c30LgjLniYamVVINMT3cgB33xAejvNWqPer8AAbgOv4dIjvM2ESEZEUaXRXrGuIr4jIgUv5EN+G5ql5xTwwa9n+K4qINCJKIjX01Hur+P2zC9mxe1/coYiIpA0lkRoaN7IXm3fs4cl3NQBMRKSckkgNDevdnsMOacXkN5fR2M4jiYhURUmkhsyMsSN78UFxKQXLNsYdjohIWlASOQBnHdOF1s2ymPzm0rhDERFJC0oiB6BFkywuyO/Os/NXs6Z0Z9zhiIjETknkAF06sif73Hlg1vK4QxERiZ2SyAHq2SGHkwZ0ZOqs5ezeWxZ3OCIisVISqYWxI3uybusunplfvP/KIiINmJJILRzfL4/euTk6wS4ijZ6SSC1kZBiXjujJ28s38V7R5rjDERGJjZJILZ07pBstmmQyecbSuEMREYmNkkgttWmezdnHdOXJd1exYdvuuMMREYmFkshBGDeqF7v3ljHtrRX7rywi0gApiRyE/p1aMbJPB+6fuYy9+zTcV0QaHyWRgzRuVE9WbtrBCx+u3X9lEZEGRknkIH3p8E50adOMKTOWxh2KiEjKKYkcpKzMDC4Z0ZM3CtezaM2WuMMREUmppCURM5tkZmvNbH5C2TQzmxumpWY2N5T3MrMdCcvuTFhniJm9Z2aFZjbBzCyUtzez6Wa2KLy2S9Zn2Z8xQ7vTJCuDKTP0+FwRaVyS2RK5Fzg1scDdL3T3Qe4+CHgM+EfC4sXly9z92oTyO4CrgX5hKt/mjcAL7t4PeCG8j0WHlk352sAuPPZ2EaU798QVhohIyiUtibj7q8CGypaF1sQFwIPVbcPMOgOt3X2mR48TnAKcFRafCUwO85MTymMxblRPtu/ex2NziuIMQ0QkpeI6JzIaWOPuixLKepvZO2b2ipmNDmVdgcRv5aJQBtDJ3cvvgLga6FTVzsxsvJkVmFlBSUlJHX2EzxrYrS2DurflvhnLKCvT43NFpHGIK4lcxGdbIcVAD3c/Bvg+MNXMWtd0Y6GVUuU3t7tPdPd8d8/Py8urbcz7ddmoXixZt43XC9clbR8iIukk5UnEzLKAc4Bp5WXuvsvd14f5OcBioD+wEuiWsHq3UAawJnR3lXd7xX6hxmlHHUJuyya6u6+INBpxtES+BHzo7p90U5lZnpllhvk+RCfQl4TuqlIzGxHOo4wFngirPQmMC/PjEspj0zQrk4uG9eDFhWtZvn573OGIiCRdMof4PgjMAAaYWZGZXRkWjeHzJ9SPB+aFIb+PAte6e/lJ+euAu4FCohbKM6H8ZuAUM1tElJhuTtZnORCXDO9Jhhn3z9JwXxFp+Cw6ndB45Ofne0FBQVL38a0H3ub1wnXMvOlkmjfJTOq+RERSwczmuHt+xXJdsZ4EY0f2ZPOOPTwxd+X+K4uI1GNKIkkwrHd7DjukFZNnLKOxtfREpHFREkkCM2PcqF4sKC7lraUb4w5HRCRplESS5MxBXWjdLEuPzxWRBk1JJElaNMniwqHdeW7+alZv3hl3OCIiSaEkkkSXjujFPnemariviDRQSiJJ1KNDC744oCNTZy9n1959cYcjIlLnlESSbOyoXqzbuptn56+OOxQRkTqnJJJkow/NpXduDvfqfloi0gApiSRZRoYxdmRP3lm+iXlFm+IOR0SkTimJpMC5Q7rRokkmk17/OO5QRETqlJJICrRuls2lI3vyz7mrePwdPflQRBoOJZEU+cGXBzCsd3t+/Nh76tYSkQZDSSRFsjMzuOOSweS1bMr4KXNYu0UXIIpI/ackkkIdWjZl4tghbN6xh2/e/7auHRGRek9JJMWO7NKGP5x/NHOWbeTn/3xfd/kVkXpNSSQGZwzszPUnHcq0ghXcN1O3RBGR+ktJJCbfP6U/Xzq8I//9rw+YsXh93OGIiNSKkkhMMjKMP144iN65OVz3wBxWbNged0giIgdMSSRGrZplc9fYfPaVOVdPKWDbrr1xhyQickCSlkTMbJKZrTWz+QllvzSzlWY2N0ynJyy7ycwKzWyhmX0lofzUUFZoZjcmlPc2s1mhfJqZNUnWZ0mm3rk5/OniwXy0Zgs/eORdnWgXkXolmS2Re4FTKyn/o7sPCtPTAGZ2BDAGODKs81czyzSzTOAvwGnAEcBFoS7ALWFbhwIbgSuT+FmS6oT+edx02uE8M381f36xMO5wRERqLGlJxN1fBTbUsPqZwEPuvsvdPwYKgWFhKnT3Je6+G3gIONPMDPgi8GhYfzJwVp1+gBS7anRvzj6mK7dO/4jn39dt40WkfojjnMj1ZjYvdHe1C2VdgRUJdYpCWVXlHYBN7r63QnmlzGy8mRWYWUFJSUldfY46ZWb87pyjGNitDd+bNpeP1myJOyQRkf1KdRK5A+gLDAKKgVtTsVN3n+ju+e6en5eXl4pd1kqz7Ez+dukQmjfJ4uopBWzavjvukEREqpXSJOLua9x9n7uXAXcRdVcBrAS6J1TtFsqqKl8PtDWzrArl9V7nNs3526WDKd60k28/+A5795XFHZKISJVSmkTMrHPC27OB8pFbTwJjzKypmfUG+gGzgbeAfmEkVhOik+9PejSE6SXgvLD+OOCJVHyGVBjSsz2/OesLvLZoHTc/82Hc4YiIVClr/1Vqx8weBE4Ecs2sCPgFcKKZDQIcWApcA+Du75vZw8AHwF7gW+6+L2zneuA5IBOY5O7vh138GHjIzH4DvAPck6zPEocLhnbng+JS7n79Yw7v3Jpzh3SLOyQRkc+xxnZdQn5+vhcUFMQdRo3s2VfG2HtmM2f5Rh6+ZiSDureNOyQRaaTMbI6751cs1xXraSw7M4O/XDKYjq2acs19Bawt1TNIRCS9KImkufY5TbhrbD5bdu7l6ikFbNWtUUQkjSiJ1AOHd27N7WOOYf6qUq6eXMDOPXqYlYikByWReuKUIzrxh/MHMvPj9Vw/9W32aOiviKQBJZF65OxjuvHrM7/Afxas5b8efpd9ZY1rUISIpJ+kDfGV5PjGiJ5s2bmXW579kJymmfzP2UcR3UpMRCT1lETqoW+e2Jetu/bwl5cW07JpFj85/XAlEhGJhZJIPfWDLw9g68693PXax7Rqls0NJ/eLOyQRaYSUROopM+MXXzuSLbv2ctv0j2jZNIsrjusdd1gi0sgoidRjGRnG788dyPZd+/jVvz+gZbMsLsjvvv8VRUTqiEZn1XNZmRncftEgRvfL5cbH5vHUvOK4QxKRRkRJpAFomhU9h2Rwj3Z8d9o7vLRwbdwhiUgjoSTSQLRoksWky4fSv1Mrrr1vDrOWrI87JBFpBJREGpDWzbKZcsUwurVrzpWTC5hXtCnukESkgVMSaWA6tGzKA1eNoG2LbMZOmq1ntYtIUimJNECHtGnGA1cNp0lmBt+4exbL12+POyQRaaCURBqonh1yuP+q4ezZV8bFd89k9WY9i0RE6p6SSAPWv1MrJl8xjE3b93DJ3TNZv3VX3CGJSAOjJNLADezWlnvG5VO0cQeX3jObjdt2xx2SiDQgSiKNwPA+HZg4Np/Ckq1cfPcsNiiRiEgdSVoSMbNJZrbWzOYnlP2vmX1oZvPM7HEzaxvKe5nZDjObG6Y7E9YZYmbvmVmhmU2wcLtaM2tvZtPNbFF4bZesz9IQnNA/j7vH5rOkZCsX3zVTiURE6kQyWyL3AqdWKJsOfMHdBwIfATclLFvs7oPCdG1C+R3A1UC/MJVv80bgBXfvB7wQ3ks1ju+fx93j8vl43TYuvkvnSETk4CUtibj7q8CGCmXPu/ve8HYm0K26bZhZZ6C1u890dwemAGeFxWcCk8P85IRyqcbofnlMumwoS9dv4+K7ZrFOiUREDkKc50SuAJ5JeN/bzN4xs1fMbHQo6woUJdQpCmUAndy9/G6Dq4FOVe3IzMabWYGZFZSUlNRR+PXXsYfmMmncUJZt2MZFE2dSskWJRERqJ5YkYmY/BfYCD4SiYqCHux8DfB+Yamata7q90Eqp8oHj7j7R3fPdPT8vL+8gIm84Rh2ay98vG0bRxh1cdNdM1m7RdSQicuBSnkTM7DLgq8Al4csfd9/l7uvD/BxgMdAfWMlnu7y6hTKANaG7q7zbS7euPUAj+3bg75cPZeXGHVw0cSZrS5VIROTApDSJmNmpwI+Ar7v79oTyPDPLDPN9iE6gLwndVaVmNiKMyhoLPBFWexIYF+bHJZTLARjRpwP3Xj6U4s07GTNxJmuUSETkACRziO+DwAxggJkVmdmVwJ+BVsD0CkN5jwfmmdlc4FHgWncvPyl/HXA3UEjUQik/j3IzcIqZLQK+FN5LLQzv04HJVwxjTWmUSHSLFBGpKQs9So1Gfn6+FxQUxB1GWpqzbAPjJr1FbssmPDh+BJ3bNI87JBFJE2Y2x93zK5brinX5xJCe7Zl8xTDWbd3NmIkzWbVpR9whiUiaUxKRzxjSsx1TrhzGhpBIViqRiEg1lETkcwb3aMd9Vw1n4/bdjJk4g6KNeh6JiFROSUQqNah7W+6/cjibtu9hzMSZrNigRCIin6ckIlU6untbHrhqOKU7lEhEpHJKIlKtgd3aMvXqEWzdtZcL/zaDxSVb4w5JRNJIjZKImeWYWUaY729mXzez7OSGJuniC13bMPXq4ezaW8YFd85g/srNcYckImmipi2RV4FmZtYVeB64lOhW79JIHNmlDY9cO5Jm2ZlcNHEms5asjzskEUkDNU0iFm5Tcg7wV3c/HzgyeWFJOuqT15JHrh1Jx9ZNGTtpNi9+uCbukEQkZjVOImY2ErgEeCqUZSYnJElnXdo25+FrRtK/UyvGT5nDE3NX7n8lEWmwappEvkv0FMLH3f39cJPEl5IXlqSzDi2bMvXq4Qzp2Y7vTpvLfTOXxR2SiMSkRknE3V9x96+7+y3hBPs6d78hybFJGmvVLJvJVwzj5MM68rN/zufPLy6isd2HTURqPjprqpm1NrMcYD7wgZn9MLmhSbprlp3JHd8YwtnHdOUPz3/E/zy9QIlEpJGpaXfWEe5eSvQc82eA3kQjtKSRy87M4Nbzj+ayUb2467WP+fFj89i7ryzusEQkRbJqWC87XBdyFvBnd99jZvqXUwDIyDB+8bUjaNM8m9tfWETpjr3cftEgmmZp7IVIQ1fTlsjfgKVADvCqmfUESpMVlNQ/Zsb3TunPz796BM++v5or7y1g2669cYclIklW0xPrE9y9q7uf7pFlwElJjk3qoSuO680fzj+aGUvWc8nds9i0fXfcIYlIEtX0xHobM7vNzArCdCtRq0Tkc84b0o2/XjKYD1aVcuHfZrJWz20XabBq2p01CdgCXBCmUuDvyQpK6r+vHHkI914+lKKN2znvzhksX687AIs0RDVNIn3d/RfuviRM/w302d9KZjbJzNaa2fyEsvZmNt3MFoXXdqHczGyCmRWa2TwzG5ywzrhQf5GZjUsoH2Jm74V1JpiZ1fyjS7KNOjSXB64eQenOPZx355ssXL0l7pBEpI7VNInsMLPjyt+Y2bFATZ6bei9waoWyG4EX3L0f8EJ4D3Aa0C9M44E7wr7aA78AhgPDgF+UJ55Q5+qE9SruS2I2qHtbHrlmJGZw/p1v8ubidXGHJCJ1qKZJ5FrgL2a21MyWAn8GrtnfSu7+KrChQvGZwOQwP5lo2HB5+ZRw4n4m0NbMOgNfAaa7+wZ33whMB04Ny1q7+0yPrnCbkrAtSSP9OrXisW+OolPrZoy9ZzaPFKyIOyQRqSM1HZ31rrsfDQwEBrr7McAXa7nPTu5eHOZXA53CfFcg8dulKJRVV15USfnnmNn48kEBJSUltQxbDka3di149JujGNGnAz98dB63Pr9QV7eLNAAH9GRDdy8NV64DfP9gdx5aEEn/JnH3ie6e7+75eXl5yd6dVKFN82z+fvlQxgztzp9eLOSGh+ayc8++uMMSkYNwMI/Hre1J7DWhK4rwujaUrwS6J9TrFsqqK+9WSbmksezMDH53zlHceNph/OvdVVxy9yzWb90Vd1giUksHk0Rq24J4EigfYTUOeCKhfGwYpTUC2By6vZ4Dvmxm7cIJ9S8Dz4VlpWY2IozKGpuwLUljZsa1J/Tlr5cMZv7KzZxzx5t6drtIPVVtEjGzLWZWWsm0Beiyv42b2YPADGCAmRWZ2ZXAzcApZrYI+FJ4D/A0sAQoBO4CrgNw9w3Ar4G3wvSrUEaoc3dYZzHRzSGlnjj9qM48OH4EW3fu5Zy/vslMPXJXpN6xxnZyMz8/3wsKCuIOQxKs2LCdy/4+m+UbtnPLuQM5Z3C3/a8kIillZnPcPb9i+cF0Z4nUie7tW/CPbx7L0F7t+f7D73Lb9I80ckuknlASkbTQpkU2914+jPOHdGPCC4v43rS57NqrkVsi6a6mzxMRSbomWRn8/ryB9MrN4X+fW8iqTTv526VDaJfTJO7QRKQKaolIWjEzvnXSofzpomOYW7SJc+54k4/XbYs7LBGpgpKIpKWvHd2FB68ezuYdezj7r28w++OKd88RkXSgJCJpa0jP9jx+3Sja5zThG3fP4vF3iva/koiklJKIpLWeHXL4xzdHMbhnW7437V1+9s/5OuEukkaURCTttW3RhPuuHM7Vo3tz38xlnHvHm3rIlUiaUBKReiE7M4OfnnEEd43NZ/n67Zzxp9d4dv7quMMSafSURKReOeWITjx1w2j65OZw7f1z+NW/PmD33rK4wxJptJREpN7p3r4Fj1w7istG9WLSGx9zwd9mULRR3VsicVASkXqpSVYGv/z6kdxxyWAWr93KGRNe54UFa+IOS6TRURKReu20ozrzr28fR9e2zblycgG/e3oBe/ape0skVZREpN7rlZvDP64bxSXDe/C3V5dw0cSZFG/eEXdYIo2Ckog0CM2yM/nt2Udx+5hBLCgu5YwJr/PKRyVxhyXS4CmJSINy5qCuPPnt4+jYqimX/X02tz6/kH1luq28SLIoiUiD0zevJY9fdywXDOnOn14s5JK7Z7K2dGfcYYk0SEoi0iA1b5LJLecN5A/nH83cFZs4fcLrvFG4Lu6wRBocJRFp0M4b0o0nrz+Oti2y+cY9s/jd0wt07y2ROqQkIg1e/06tePL6Y7l4WDR666y/vMnC1VviDkukQUh5EjGzAWY2N2EqNbPvmtkvzWxlQvnpCevcZGaFZrbQzL6SUH5qKCs0sxtT/Vmk/mjRJIvfnn0U94zLp2TLTr7259e55/WPKdNJd5GDYu7x/RGZWSawEhgOXA5sdfc/VKhzBPAgMAzoAvwH6B8WfwScAhQBbwEXufsH1e0zPz/fCwoK6vJjSD2zbusubnxsHv9ZsJbjDs3lD+cfzSFtmsUdlkhaM7M57p5fsTzu7qyTgcXuvqyaOmcCD7n7Lnf/GCgkSijDgEJ3X+Luu4GHQl2RauW2bMpdY/P53TlHMWfZRr7yf6/y1LziuMMSqZfiTiJjiFoZ5a43s3lmNsnM2oWyrsCKhDpFoayq8s8xs/FmVmBmBSUlugBNome5XzSsB09/ZzS9cnP41tS3+f60uZTu3BN3aCL1SmxJxMyaAF8HHglFdwB9gUFAMXBrXe3L3Se6e7675+fl5dXVZqUB6J2bw6PXjuQ7J/fjiXdXcdr/vabnuYscgDhbIqcBb7v7GgB3X+Pu+9y9DLiLqLsKonMm3RPW6xbKqioXOSDZmRl875T+PHLtSLIyjQsnzuCWZz/Uc0pEaiDOJHIRCV1ZZtY5YdnZwPww/yQwxsyamllvoB8wm+hEej8z6x1aNWNCXZFaGdyjHU/fMJoL87tzx8uLOfuvb7BojYYCi1QnliRiZjlEo6r+kVD8ezN7z8zmAScB3wNw9/eBh4EPgGeBb4UWy17geuA5YAHwcKgrUms5TbO4+dyBTLx0CMWbd/LVP73OvW98TJyjGEXSWaxDfOOgIb5SU2u37OTHj87jpYUljO4XDQXu1FpDgaVxStchviJpq2OrZky6bCi/OesLvLV0A6fc9gpTZy3XBYoiCZRERKphZnxjRE+eumE0h3duzU8ef4/z7nyTBcWlcYcmkhaURERqoG9eSx4aP4Jbzz+apeu389U/vc7/PL2Abbv2xh2aSKyURERqyMw4d0g3XvyvE7ggvxsTX13CKbe9wvPvr447NJHYKImIHKC2LZrwu3MG8tg3R9K6eTbj75vDVZPfomjj9rhDE0k5JRGRWhrSsz3/+vZx/OT0w3ijcBCXsPoAABLDSURBVD2n3PYqd76ymD37dJGiNB5KIiIHITszg/HH9+U//3UCo/vlcvMzH/LVCa/z1lLdOkUaByURkTrQtW1zJo7N566x+WzdtZfz75zBjx+dx8Ztu+MOTSSplERE6tApR3Ri+veP55oT+vDY20WcfNsrPFKwQle8S4OlJCJSx1o0yeKm0w7n3zccR5/cHH746DwunDhT9+GSBklJRCRJDjukNQ9fM5Jbzj2Kj9Zs4dTbX+OHj7zLig0axSUNR1bcAYg0ZBkZxoVDe/Clwzvx15cXc9/MZTz+zkouGNqdb3/xUDq3aR53iCIHRTdgFEmh1Zt38peXCnnoreWYGRcP68F1J/WlYyvd2FHSW1U3YFQSEYlB0cbt/PnFQh6ZU0R2pjFuZC+uOaEv7XOaxB2aSKWURAIlEUknS9dtY8ILi3h87kpaZGdyxXG9uWp0H9o0z447NJHPUBIJlEQkHRWu3cIf/7OIp+YV06pZFuNH9+Hy43rTsqlOW0p6UBIJlEQknX2wqpQ//ucjpn+whnYtsrn2hL6MHdmL5k0y4w5NGjklkUBJROqDd1ds4rbpH/HKRyXktmzKdSf25eLhPWiWrWQi8VASCZREpD4pWLqBW5//iBlL1tOpdVMuP7Y3Fw3roXMmknJKIoGSiNRHbxau468vL+b1wnXkNMnkwqE9uPzYXnRv3yLu0KSRSLtnrJvZUjN7z8zmmllBKGtvZtPNbFF4bRfKzcwmmFmhmc0zs8EJ2xkX6i8ys3FxfR6RZBp1aC73XzWcp244ji8feQhTZizlxD+8zPVT32Ze0aa4w5NGLLaWiJktBfLdfV1C2e+BDe5+s5ndCLRz9x+b2enAt4HTgeHA7e4+3MzaAwVAPuDAHGCIu2+sar9qiUhDULx5B/e+sZSps5azZddehvduz/jj+3DSgI5kZFjc4UkDlHYtkSqcCUwO85OBsxLKp3hkJtDWzDoDXwGmu/uGkDimA6emOmiRVOvcpjk3nX44b970Rf7fGYezYsN2rpxcwCl/fIUHZy9n5559cYcojUScScSB581sjpmND2Wd3L04zK8GOoX5rsCKhHWLQllV5Z9hZuPNrMDMCkpKSuryM4jEqlWzbK4a3YdXfnQSt48ZRLPsTG76x3scd8uLTHhhERv0PBNJsjivZDrO3VeaWUdgupl9mLjQ3d3M6qSvzd0nAhMh6s6qi22KpJPszAzOHNSVrx/dhRlL1nPXq0u4bfpH/PXlQs4f0p0rj+tNr9ycuMOUBii2JOLuK8PrWjN7HBgGrDGzzu5eHLqr1obqK4HuCat3C2UrgRMrlL+c5NBF0paZMapvLqP65vLRmi3c/doSpr21gvtnLeNLh3fikuE9GN0vj0ydN5E6EsuJdTPLATLcfUuYnw78CjgZWJ9wYr29u//IzM4ArufTE+sT3H1YOLE+BygfrfU20Yn1Kh9wrRPr0tis3bKTyW8u5cHZK9iwbTdd2zbngvzuXDC0m25FLzWWVteJmFkf4PHwNguY6u6/NbMOwMNAD2AZcIG7bzAzA/5MdNJ8O3C5u5cPC74C+EnY1m/d/e/V7VtJRBqrXXv3Mf2DNTw0ewWvF64jw+CkAR0ZM6wHJw3IIysz3cbZSDpJqyQSJyUREVi+fjvTCpbzSEERa7fsolPrppw/pDsXDu2uCxilUkoigZKIyKf27ivjxQ/X8tBbK3h54VocOO7QXMYM7cEpR3SiSZZaJxJREgmUREQqt2rTDh4pKOLhghWs3LSDDjlNOG9INy4c2p0+eS3jDk9ipiQSKImIVG9fmfPqohIemr2cFxasZW+ZM7x3e8YM684pRxyiZ5w0UkoigZKISM2t3bKTR+cUMe2tFSxbv50mWRmcNCCPMwZ24eTDOpKjhNJoKIkESiIiB66szHl7+Uaeeq+Yp98rZk3pLppmZfDFwzpyxsDOfPGwjrRoooTSkCmJBEoiIgenrMyZs3wjT80r5qn3iinZsotm2RmcfFgnzhjYmZMGdNSTGBsgJZFASUSk7uwrcwqWbggtlNWs27qL5tmZnHx4R746sDMnDuiopzE2EEoigZKISHLsK3Nmf7yBf89bxbPzV7N+225ymmRy8uFRC+WE/nlKKPWYkkigJCKSfHv3lTHr4w38e14xz84vZuP2PbRoksmxh+Zy0oCOnDggjy5tdcuV+kRJJFASEUmtvfvKmLFkPc+9v5qXPixh5aYdABx2SCtOHNCRkwbkMbhnO7J125W0piQSKImIxMfdWVyylZc+LOGlhWuZ/fEG9pY5rZplMbpfLicO6MiJ/fPo2LpZ3KFKBUoigZKISPrYsnMPbxSu5+WFa3lp4VrWlO4C4AtdW4dur44M6t5Wt65PA0oigZKISHpydxYUb+GlhWt5eeFa5izbSJlD2xbZnNA/jxP65zG0V3u6tWtOdGNvSSUlkUBJRKR+2Lx9D68uirq9XllYwvrwqN9OrZuS37M9Q3q2I79XO47o3Fq3sU+BqpKILjEVkbTUpkU2Xzu6C187ugtlZc6C1aXMWbaRgqUbmbMsunoeoEWTTAZ1b0t+z3YM6dWewT3a0qpZdszRNx5qiYhIvbRq0w4Klm1kztINFCzbyILiUsoczOCwQ1qTH1oq+b3a01XDiQ+aurMCJRGRhmnrrr28s/zTlso7yzeybfc+ADq3acbgnu0Y2LUNR3Vtw5Fd29CmuVorB0LdWSLSoLVsmsXofnmM7pcHRNenfLh6CwWhpfLO8k08Na/4k/o9O7TgCyGpHNW1DV/o0oY2LZRYDpRaIiLSaKzfuov5q0qZv3Iz7xVt5r2Vmz+5+BGUWKqTNi0RM+sOTAE6AQ5MdPfbzeyXwNVASaj6E3d/OqxzE3AlsA+4wd2fC+WnArcDmcDd7n5zKj+LiNQvHVo2/WS4cLkN23ZHSSUklrkVWiw92rcIXWCt6ZPbkj55OfRo30L3AQtS3hIxs85AZ3d/28xaAXOAs4ALgK3u/ocK9Y8AHgSGAV2A/wD9w+KPgFOAIuAt4CJ3/6C6/aslIiL7k5hYyl+LNn7aYjGDLm2a0ycvh9650dQrN4c+uTl0bdu8QQ45TpuWiLsXA8VhfouZLQC6VrPKmcBD7r4L+NjMCokSCkChuy8BMLOHQt1qk4iIyP60z2nC8f3zOD6hxVK6cw9L123j4wrT42+vZMuuvZ/Uy840urdvQZ/c8gTTkl65LeiT25JOrZs2uAslYz2xbma9gGOAWcCxwPVmNhYoAP7L3TcSJZiZCasV8WnSWVGhfHgV+xkPjAfo0aNH3X0AEWk0WjfLZmC3tgzs1vYz5e7O+m27P5tcSraxdP02Xlu0jl17yz6pm9Mkkz55UZdY34TX3rk59bZ7LLYkYmYtgceA77p7qZndAfya6DzJr4FbgSvqYl/uPhGYCFF3Vl1sU0QEwMzIbdmU3JZNGdqr/WeWlZU5xaU7WbpuG0tKtrK4ZBtL1m2jYOlGnnx3FeVnE8q7x/p2bEmf3Bz6dmxJ39wc+uSlf+slliRiZtlECeQBd/8HgLuvSVh+F/Dv8HYl0D1h9W6hjGrKRURil5FhdG3bnK5tm3PsobmfWbZj9z4+XreNJeu2snhteC3ZSsHSDWwP17fAp62X3rk5dGnbnC5tm9G5TXM6t2lGl7bNadciO9YkE8foLAPuARa4+20J5Z3D+RKAs4H5Yf5JYKqZ3UZ0Yr0fMBswoJ+Z9SZKHmOAi1PzKUREDk7zJpkc0aU1R3Rp/Zlyd2d16U6WlGxjccnWT17fXr6RZ+YXs2ffZztTmmVnfJJUOrdJSDJtm9ElvLZO4m1g4miJHAtcCrxnZnND2U+Ai8xsEFF31lLgGgB3f9/MHiY6Yb4X+Ja77wMws+uB54iG+E5y9/dT+UFEROqamYWk8PnWS1mZs27rLlZt3knxph2fvBZv3smqzTt4o3Ada7fspKxCp33Lpll0btOMOy8dQt+8lnUbry42FBFpOPbuK2PNll2fTzKbdvC7c46iQ8umtdpu2gzxFRGR5MnKzPjkPEwqNLwrYkREJGWUREREpNaUREREpNaUREREpNaUREREpNaUREREpNaUREREpNaUREREpNYa3RXrZlYCLKvl6rnAujoMp64pvoOj+A6O4js46R5fT3fPq1jY6JLIwTCzgsou+08Xiu/gKL6Do/gOTrrHVxV1Z4mISK0piYiISK0piRyYiXEHsB+K7+AovoOj+A5OusdXKZ0TERGRWlNLREREak1JREREak1JpBJmdqqZLTSzQjO7sZLlTc1sWlg+y8x6pTC27mb2kpl9YGbvm9l3KqlzopltNrO5Yfp5quIL+19qZu+FfX/uMZIWmRCO3zwzG5zC2AYkHJe5ZlZqZt+tUCelx8/MJpnZWjObn1DW3symm9mi8NquinXHhTqLzGxcCuP7XzP7MPz8HjeztlWsW+3vQhLj+6WZrUz4GZ5exbrV/q0nMb5pCbEtTXhUeMV1k378Dpq7a0qYiJ7XvhjoAzQB3gWOqFDnOuDOMD8GmJbC+DoDg8N8K+CjSuI7Efh3jMdwKZBbzfLTgWcAA0YAs2L8Wa8muogqtuMHHA8MBuYnlP0euDHM3wjcUsl67YEl4bVdmG+Xovi+DGSF+Vsqi68mvwtJjO+XwA9q8POv9m89WfFVWH4r8PO4jt/BTmqJfN4woNDdl7j7buAh4MwKdc4EJof5R4GTzcxSEZy7F7v722F+C7AA6JqKfdehM4EpHpkJtDWzzjHEcTKw2N1reweDOuHurwIbKhQn/o5NBs6qZNWvANPdfYO7bwSmA6emIj53f97d94a3M4Fudb3fmqri+NVETf7WD1p18YXvjQuAB+t6v6miJPJ5XYEVCe+L+PyX9Cd1wh/SZqBDSqJLELrRjgFmVbJ4pJm9a2bPmNmRKQ0MHHjezOaY2fhKltfkGKfCGKr+443z+AF0cvfiML8a6FRJnXQ5jlcQtSwrs7/fhWS6PnS3TaqiOzAdjt9oYI27L6pieZzHr0aUROopM2sJPAZ8191LKyx+m6iL5mjgT8A/Uxzece4+GDgN+JaZHZ/i/e+XmTUBvg48UsniuI/fZ3jUr5GWY/HN7KfAXuCBKqrE9btwB9AXGAQUE3UZpaOLqL4VkvZ/S0oin7cS6J7wvlsoq7SOmWUBbYD1KYku2mc2UQJ5wN3/UXG5u5e6+9Yw/zSQbWa5qYrP3VeG17XA40TdBolqcoyT7TTgbXdfU3FB3McvWFPexRde11ZSJ9bjaGaXAV8FLgmJ7nNq8LuQFO6+xt33uXsZcFcV+437+GUB5wDTqqoT1/E7EEoin/cW0M/Meof/VscAT1ao8yRQPhLmPODFqv6I6lroQ70HWODut1VR55DyczRmNozo55ySJGdmOWbWqnye6ATs/ArVngTGhlFaI4DNCV03qVLlf4BxHr8Eib9j44AnKqnzHPBlM2sXumu+HMqSzsxOBX4EfN3dt1dRpya/C8mKL/Ec29lV7Lcmf+vJ9CXgQ3cvqmxhnMfvgMR9Zj8dJ6LRQx8Rjdz4aSj7FdEfDEAzom6QQmA20CeFsR1H1LUxD5gbptOBa4FrQ53rgfeJRpvMBEalML4+Yb/vhhjKj19ifAb8JRzf94D8FP98c4iSQpuEstiOH1EyKwb2EPXLX0l0ju0FYBHwH6B9qJsP3J2w7hXh97AQuDyF8RUSnU8o/x0sH63YBXi6ut+FFMV3X/jdmkeUGDpXjC+8/9zfeiriC+X3lv/OJdRN+fE72Em3PRERkVpTd5aIiNSakoiIiNSakoiIiNSakoiIiNSakoiIiNSakohIHTCzfRXuDlxnd4Q1s16Jd4AVSSdZcQcg0kDscPdBcQchkmpqiYgkUXgexO/DMyFmm9mhobyXmb0YbhD4gpn1COWdwvM53g3TqLCpTDO7y6JnyDxvZs1D/RsserbMPDN7KKaPKY2YkohI3WheoTvrwoRlm939KODPwP+Fsj8Bk919INHNCyeE8gnAKx7d/HEw0ZXKAP2Av7j7kcAm4NxQfiNwTNjOtcn6cCJV0RXrInXAzLa6e8tKypcCX3T3JeHGmavdvYOZrSO6FceeUF7s7rlmVgJ0c/ddCdvoRfTckH7h/Y+BbHf/jZk9C2wlutPwPz3cOFIkVdQSEUk+r2L+QOxKmN/Hp+czzyC6D9lg4K1wZ1iRlFESEUm+CxNeZ4T5N4nuGgtwCfBamH8B+CaAmWWaWZuqNmpmGUB3d38J+DHRIwk+1xoSSSb91yJSN5qb2dyE98+6e/kw33ZmNo+oNXFRKPs28Hcz+yFQAlweyr8DTDSzK4laHN8kugNsZTKB+0OiMWCCu2+qs08kUgM6JyKSROGcSL67r4s7FpFkUHeWiIjUmloiIiJSa2qJiIhIrSmJiIhIrSmJiIhIrSmJiIhIrSmJiIhIrf1/+OdMa2h9a20AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n",
      "経過時間：242.40701818466187\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "all_epoch_losses = []\n",
    "all_iter_losses = []\n",
    "\n",
    "print(\"training ...\")\n",
    "\n",
    "\n",
    "# epoch = 0\n",
    "for epoch in range(epoch_num):\n",
    "    \n",
    "    epoch_loss = 0 # epoch毎のloss\n",
    "\n",
    "    # i = 0\n",
    "    for i in range(iter_per_epoch):\n",
    "\n",
    "        # 勾配の初期化\n",
    "        encoder_optimizer.zero_grad()\n",
    "        decoder_optimizer.zero_grad()\n",
    "\n",
    "        # データをテンソルに変換\n",
    "        input_ts, _, output_ts, __, ___ = batch2TrainData(\n",
    "            voc, [random.choice(pairs) for _ in range(batch_size)]\n",
    "        )\n",
    "        input_ts = input_ts.T # これでOK。EOSがあるままで良いと思う。貴重な情報。\n",
    "        output_ts = output_ts.T\n",
    "        sos = torch.ones(output_ts.shape[0], 1, dtype=int, device=device)  # GPU指定\n",
    "        output_ts = torch.cat((sos, output_ts), 1)  # SOS_token 1 を先頭にくっつければ良さそう。\n",
    "\n",
    "        # Encoderの順伝搬\n",
    "        encoder_state = encoder(input_ts)\n",
    "\n",
    "        # Decoderに教師強制で入力する文。次の単語は？のモデルなので最後の単語は使わない。\n",
    "        source = output_ts[:, :-1]\n",
    "\n",
    "        # Decoderの教師データ。次の単語は？のモデルなので SOS token 1 を削る。\n",
    "        target = output_ts[:, 1:]\n",
    "\n",
    "        loss = 0\n",
    "        # 学習時はDecoderはこのように１回呼び出すだけでグルっと系列をループしているからこれでOK\n",
    "        decoder_output, _ = decoder(source, encoder_state)\n",
    "\n",
    "        for j in range(decoder_output.size()[1]):\n",
    "            # バッチ毎にまとめてloss計算\n",
    "            loss += criterion(decoder_output[:, j, :], target[:, j])\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "        all_iter_losses.append(loss.item())\n",
    "\n",
    "        # 誤差逆伝播\n",
    "        loss.backward()  # これでいける。\n",
    "        # loss には criterion の返却値がスタックされていて、\n",
    "        # criterion には decoder の output が渡されていて、\n",
    "        # decoder の output が得られるまでの演算過程が内部で保存されているので、\n",
    "        # loss.backward() を引金に一気に back prop される。\n",
    "\n",
    "        # パラメータ更新\n",
    "        # Encoder、Decoder両方学習\n",
    "        encoder_optimizer.step()\n",
    "        decoder_optimizer.step()  # これでいける。\n",
    "        # 両 optimizer インスタンス生成時にすでにパラメータオブジェクトへのパスが通っていて、\n",
    "        # パラメータオブジェクト自体に勾配が記録されているので、これで OK。\n",
    "\n",
    "    # 損失を表示\n",
    "    print(\"Epoch %d: %.2f\" % (epoch+1, epoch_loss))\n",
    "    all_epoch_losses.append(epoch_loss)\n",
    "    if epoch_loss < 1: break\n",
    "\n",
    "plt.plot(all_epoch_losses)\n",
    "plt.title(\"Learning Curve (Epoch)\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.show()\n",
    "# fig = plt.figure()\n",
    "plt.plot(all_iter_losses)\n",
    "plt.title(\"Learning Curve (Iteration)\")\n",
    "plt.xlabel(\"Iterations\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.show()\n",
    "# fig.savefig(\"learning_curve_seq2seq.png\")\n",
    "\n",
    "print(\"Done\")\n",
    "\n",
    "elapsed_time = time.time() - start\n",
    "print(f\"経過時間：{elapsed_time}\")\n",
    "\n",
    "# 計算の量 : ローカル CPU : Colab GPU\n",
    "# 100iters : ２分         : ２秒\n",
    "# 5epochs  : １時間       : １分\n",
    "# 20epochs :  ー          : ４分    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VWOd6xPOP7RN"
   },
   "source": [
    "# 学習したモデル等の保存"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BD_wgnYgWYgb"
   },
   "outputs": [],
   "source": [
    "\n",
    "# モデルの保存\n",
    "# torch.save(encoder.state_dict(), \"/content/drive/My Drive/chatbot/encoder_20epoch.pt\")\n",
    "# torch.save(decoder.state_dict(), \"/content/drive/My Drive/chatbot/decoder_20epoch.pt\")\n",
    "# マウントされてる場所にちゃんと保存する。\n",
    "\n",
    "# 辞書も保存しておく\n",
    "# with open(\"/content/drive/My Drive/chatbot/word2index_CornellMovie.pkl\", \"wb\") as f:\n",
    "#     pickle.dump(voc.word2index, f) #保存\n",
    "# with open(\"/content/drive/My Drive/chatbot/index2word_CornellMovie.pkl\", \"wb\") as f:\n",
    "#     pickle.dump(voc.index2word, f) #保存\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ELpQ_vRRWp9L"
   },
   "source": [
    "# モデル等の読み込み\n",
    "\n",
    "- 上記セルで学習したモデルをそのまま使う\n",
    "- or 以前に学習済みのモデルを使う\n",
    "\n",
    "辞書についてもどちらか。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 12012,
     "status": "ok",
     "timestamp": 1596178886811,
     "user": {
      "displayName": "Rui ds",
      "photoUrl": "",
      "userId": "05602141477976220902"
     },
     "user_tz": -540
    },
    "id": "EgqonWMlYVvt"
   },
   "outputs": [],
   "source": [
    "\n",
    "# 上記セルで学習したモデルをそのまま使う場合\n",
    "# encoder_loaded = encoder\n",
    "# decoder_loaded = decoder\n",
    "\n",
    "# 以前に学習済みのモデルを使う場合\n",
    "encoder_loaded = Encoder(vocab_size=7826, embedding_dim=500, hidden_dim=500).to(device)  # GPU\n",
    "decoder_loaded = Decoder(vocab_size=7826, embedding_dim=500, hidden_dim=500).to(device)  # GPU\n",
    "# encoder_loaded.load_state_dict(torch.load(\"/content/drive/My Drive/chatbot/encoder_20epoch.pt\"))\n",
    "# decoder_loaded.load_state_dict(torch.load(\"/content/drive/My Drive/chatbot/decoder_20epoch.pt\"))\n",
    "encoder_loaded.load_state_dict(torch.load(\"/content/chatbot/encoder_20epoch.pt\"))\n",
    "decoder_loaded.load_state_dict(torch.load(\"/content/chatbot/decoder_20epoch.pt\"))\n",
    "\n",
    "\n",
    "# 上記で作った辞書をそのまま使う\n",
    "# index2word = voc.index2word\n",
    "# word2index = voc.word2index\n",
    "\n",
    "# 前に作った辞書を読み込む\n",
    "# with open(\"/content/drive/My Drive/chatbot/index2word_CornellMovie.pkl\", \"rb\") as f:\n",
    "#     index2word = pickle.load(f)\n",
    "# with open(\"/content/drive/My Drive/chatbot/word2index_CornellMovie.pkl\", \"rb\") as f:\n",
    "#     word2index = pickle.load(f)\n",
    "with open(\"/content/chatbot/index2word_CornellMovie.pkl\", \"rb\") as f:\n",
    "    index2word = pickle.load(f)\n",
    "with open(\"/content/chatbot/word2index_CornellMovie.pkl\", \"rb\") as f:\n",
    "    word2index = pickle.load(f)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0sgsecNsc6lQ"
   },
   "source": [
    "# チャットボットの補助的な関数を定義"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 582,
     "status": "ok",
     "timestamp": 1596178891812,
     "user": {
      "displayName": "Rui ds",
      "photoUrl": "",
      "userId": "05602141477976220902"
     },
     "user_tz": -540
    },
    "id": "dfpU3abvdLTr"
   },
   "outputs": [],
   "source": [
    "\n",
    "# Unicode 文字列を ASCII に変換\n",
    "def unicodeToAscii(s):\n",
    "    return ''.join(\n",
    "        c for c in unicodedata.normalize('NFD', s)\n",
    "        if unicodedata.category(c) != 'Mn'\n",
    "    )\n",
    "\n",
    "\n",
    "# Lowercase, trim, and remove non-letter characters\n",
    "# 上記の unicodeToASCII() を呼んで ASCII にした上で、\n",
    "# すべての文字を小文字に変換し、句読点を除去し、アルファベット以外の文字を除去。\n",
    "# 正規表現で頑張っている。\n",
    "def normalizeString(s):\n",
    "    s = unicodeToAscii(s.lower().strip())\n",
    "    s = re.sub(r\"([.!?])\", r\" \\1\", s)\n",
    "    s = re.sub(r\"[^a-zA-Z.!?]+\", r\" \", s)\n",
    "    s = re.sub(r\"\\s+\", r\" \", s).strip()\n",
    "    return s\n",
    "\n",
    "\n",
    "def get_max_index(decoder_output):\n",
    "    results = []\n",
    "    for h in decoder_output:\n",
    "        results.append(torch.argmax(h))\n",
    "    return torch.tensor(results, device=device).view(1, 1)  # GPU指定\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1J8Gf-lcZWDb"
   },
   "source": [
    "# チャットボットの関数を定義"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 553,
     "status": "ok",
     "timestamp": 1596178894608,
     "user": {
      "displayName": "Rui ds",
      "photoUrl": "",
      "userId": "05602141477976220902"
     },
     "user_tz": -540
    },
    "id": "tl1Ane0ZZb6B"
   },
   "outputs": [],
   "source": [
    "\n",
    "def chatbot(user_question, encoder_model=encoder_loaded, decoder_model=decoder_loaded, word2index=word2index, index2word=index2word, SOS_token=1, EOS_token=2):\n",
    "    \"\"\" chatbot by seq2seq\n",
    "    \"\"\"\n",
    "    user_input = normalizeString(user_question)\n",
    "    user_input = [word2index[word] for word in user_input.split(' ')] + [EOS_token]\n",
    "    user_input = torch.LongTensor([user_input]).to(device)  # GPU指定\n",
    "\n",
    "    with torch.no_grad():\n",
    "        \n",
    "        encoder_state = encoder_model(user_input)\n",
    "        \n",
    "        # Decoderにはまず文字列生成開始を表す\"SOS\"をインプットにする\n",
    "        decoder_input_tensor = torch.tensor([[SOS_token]]).to(device)  # GPU指定\n",
    "        \n",
    "        # 文脈ベクトルを enc から dec へ\n",
    "        decoder_hidden = encoder_state\n",
    "        \n",
    "        # 結果(単語)を結合するための入れ物を定義\n",
    "        batch_tmp = torch.zeros(1,1, dtype=torch.long).to(device)  # GPU指定\n",
    "        \n",
    "        while decoder_input_tensor[0][0] != EOS_token:  # EOS が出るまで単語生成\n",
    "            decoder_output, decoder_hidden = decoder_model(decoder_input_tensor, decoder_hidden)\n",
    "            decoder_output.shape     # 予測された文字出現スコア\n",
    "            decoder_hidden[0].shape  # 次時点の(状態,記憶)のタプル\n",
    "            decoder_input_tensor = get_max_index(decoder_output[0])\n",
    "            batch_tmp = torch.cat([batch_tmp, decoder_input_tensor], dim=1)\n",
    "            \n",
    "        # 最初のbatch_tmpの0要素が先頭に残ってしまっているのでスライスして削除\n",
    "        bot_output = batch_tmp[:,1:][0]\n",
    "\n",
    "    bot_output = [index2word[int(idx)] for idx in bot_output]\n",
    "    bot_answer = \" \".join(bot_output[:-1])\n",
    "\n",
    "    return bot_answer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gbJ_1WYfa3zV"
   },
   "source": [
    " # チャットボットを動かす"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 408
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 68329,
     "status": "ok",
     "timestamp": 1596179069567,
     "user": {
      "displayName": "Rui ds",
      "photoUrl": "",
      "userId": "05602141477976220902"
     },
     "user_tz": -540
    },
    "id": "rRDu9A5Kq7Qd",
    "outputId": "13c0c895-95cd-48b0-f2cc-4e7fe53f10a3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You : Hello.\n",
      "Bot : hello .\n",
      "You : How are you?\n",
      "Bot : fine . how are you ?\n",
      "You : Me too.\n",
      "Bot : what ?\n",
      "You : what's up?\n",
      "Bot : i don t know .\n",
      "You : Where are you from?\n",
      "Bot : san francisco .\n",
      "You : What time is it now?\n",
      "Bot : eight .\n",
      "You : How much is it?\n",
      "Bot : seventy five per cent .\n",
      "You : Who are you?\n",
      "Bot : i m with you !\n",
      "You : I love you.\n",
      "Bot : i love you too frances .\n",
      "You : Who?\n",
      "Bot : i do .\n",
      "You : see you.\n",
      "Bot : no\n",
      "You : exit\n"
     ]
    }
   ],
   "source": [
    "# チャットボットを実行。 exit と打つと終了する。\n",
    "# 「未知の単語」トークンを辞書に追加するのを忘れたので、辞書に無い語を打つとエラーになる...\n",
    "\n",
    "while True:\n",
    "    q = input(\"You : \")\n",
    "    if q == \"exit\":\n",
    "        break\n",
    "    else:\n",
    "        print(\"Bot : \" + chatbot(q))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fks72cN0rT4A"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyM0UlKm0M1xkOhkreuuN2xz",
   "collapsed_sections": [],
   "name": "chatbot_seq2seq_LSTM.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
